# Model Training Notebooks

рдпрд╣ folder рдореЗрдВ рддреАрди Jupyter notebooks рд╣реИрдВ рдЬреЛ рдЖрдк **Kaggle рдкрд░ рдЪрд▓рд╛ рд╕рдХрддреЗ рд╣реИрдВ** рдФрд░ trained models рдХреЛ download рдХрд░рдХреЗ рдЗрд╕ project рдореЗрдВ use рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред

## ЁЯУЪ Notebooks

### 1. [01_topic_extraction_training.ipynb](01_topic_extraction_training.ipynb)
**Purpose**: Syllabus рд╕реЗ topics extract рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП model train рдХрд░рддрд╛ рд╣реИред

**Output**: `topic_extractor.pkl`

**What it does**:
- PDF/DOCX/TXT рд╕реЗ topics рдирд┐рдХрд╛рд▓рддрд╛ рд╣реИ
- Unit, Chapter, Week patterns рдХреЛ detect рдХрд░рддрд╛ рд╣реИ
- Subtopics рдХреЛ identify рдХрд░рддрд╛ рд╣реИ
- Clustering-based topic extraction

**Place output in**: `ml_models/nlp/topic_extractor.pkl`

---

### 2. [02_embedding_generation.ipynb](02_embedding_generation.ipynb)
**Purpose**: Video relevance scoring рдХреЗ рд▓рд┐рдП embeddings generate рдХрд░рддрд╛ рд╣реИред

**Output**: `embeddings.pkl`

**What it does**:
- Sentence-BERT model load рдХрд░рддрд╛ рд╣реИ
- Text рдХреЛ vector embeddings рдореЗрдВ convert рдХрд░рддрд╛ рд╣реИ
- Semantic similarity calculate рдХрд░рддрд╛ рд╣реИ
- Fast caching рдХреЗ рд╕рд╛рде

**Place output in**: `ml_models/nlp/embeddings.pkl`

---

### 3. [03_xgboost_ranker_training.ipynb](03_xgboost_ranker_training.ipynb)
**Purpose**: Videos рдХреЛ rank рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП ML model train рдХрд░рддрд╛ рд╣реИред

**Output**: `xgboost_ranker.pkl`

**What it does**:
- Learning-to-Rank model train рдХрд░рддрд╛ рд╣реИ
- Multiple features use рдХрд░рддрд╛ рд╣реИ (views, likes, relevance, etc.)
- nDCG metric рд╕реЗ evaluate рдХрд░рддрд╛ рд╣реИ
- Feature importance рджрд┐рдЦрд╛рддрд╛ рд╣реИ

**Place output in**: `ml_models/ranking/xgboost_ranker.pkl`

---

## ЁЯЪА Kaggle рдкрд░ рдХреИрд╕реЗ рдЪрд▓рд╛рдПрдВ?

### Step 1: Kaggle Account рдмрдирд╛рдПрдВ
1. [kaggle.com](https://www.kaggle.com) рдкрд░ рдЬрд╛рдПрдВ
2. Sign up рдХрд░реЗрдВ (free рд╣реИ!)

### Step 2: New Notebook рдмрдирд╛рдПрдВ
1. Kaggle рдкрд░ "Code" тЖТ "New Notebook" click рдХрд░реЗрдВ
2. "File" тЖТ "Upload Notebook" рд╕реЗ notebook upload рдХрд░реЗрдВ
3. рдпрд╛ рдлрд┐рд░ code рдХреЛ copy-paste рдХрд░реЗрдВ

### Step 3: Run рдХрд░реЗрдВ
1. рд╕рднреА cells рдХреЛ run рдХрд░реЗрдВ (Shift + Enter)
2. рдпрд╛ "Run All" button click рдХрд░реЗрдВ
3. Wait рдХрд░реЗрдВ рдЬрдм рддрдХ model train рд╣реЛ рдЬрд╛рдП

### Step 4: Download рдХрд░реЗрдВ
1. Output section рдореЗрдВ `.pkl` file рджрд┐рдЦреЗрдЧреА
2. Download рдХрд░реЗрдВ
3. рдЕрдкрдиреЗ project рдХреЗ рд╕рд╣реА folder рдореЗрдВ paste рдХрд░реЗрдВ

---

## ЁЯУБ File Placement

Models рдХреЛ download рдХрд░рдиреЗ рдХреЗ рдмрд╛рдж рдпрд╣рд╛рдВ рд░рдЦреЗрдВ:

```
AutoYT-Playlist/
тФФтФАтФА ml_models/
    тФЬтФАтФА nlp/
    тФВ   тФЬтФАтФА topic_extractor.pkl    тЖР Notebook 1 рд╕реЗ
    тФВ   тФФтФАтФА embeddings.pkl          тЖР Notebook 2 рд╕реЗ
    тФФтФАтФА ranking/
        тФФтФАтФА xgboost_ranker.pkl      тЖР Notebook 3 рд╕реЗ
```

---

## тЪЩя╕П System Integration

рдЬрдм рдЖрдк `.pkl` files рдХреЛ рд╕рд╣реА рдЬрдЧрд╣ рд░рдЦреЗрдВрдЧреЗ:

1. **Backend automatically detect рдХрд░реЗрдЧрд╛** рдХрд┐ models available рд╣реИрдВ
2. **Rule-based fallback рд╕реЗ switch рд╣реЛрдЧрд╛** ML-based processing рдкрд░
3. **Better results рдорд┐рд▓реЗрдВрдЧреЗ** topic extraction рдФрд░ ranking рдореЗрдВ

---

## ЁЯФз Customization

### рдЕрдкрдирд╛ data use рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ?

**Notebook 1 & 2**: 
- рдЕрдкрдиреА syllabus files upload рдХрд░реЗрдВ Kaggle dataset рдореЗрдВ
- Sample data рдХреЛ replace рдХрд░реЗрдВ

**Notebook 3**:
- Real user feedback data use рдХрд░реЗрдВ
- Synthetic data рдХреЛ replace рдХрд░реЗрдВ
- Features add/remove рдХрд░реЗрдВ

### Hyperparameters tune рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ?

рд╣рд░ notebook рдореЗрдВ parameters section рд╣реИ:
- Learning rate
- Model depth
- Clustering parameters
- etc.

---

## ЁЯУК Expected Performance

| Model | Metric | Expected Value |
|-------|--------|----------------|
| Topic Extractor | Accuracy | 85-95% |
| Embeddings | Similarity | Cosine 0-1 |
| XGBoost Ranker | nDCG@10 | 0.70-0.85 |

---

## тЭУ Troubleshooting

### "Out of Memory" error?
- Kaggle рдореЗрдВ GPU/TPU enable рдХрд░реЗрдВ
- Batch size рдХрдо рдХрд░реЗрдВ
- Smaller model use рдХрд░реЗрдВ

### Model load рдирд╣реАрдВ рд╣реЛ рд░рд╣рд╛?
- Check рдХрд░реЗрдВ file path рд╕рд╣реА рд╣реИ
- Verify рдХрд░реЗрдВ `.pkl` extension рд╣реИ
- Backend logs рджреЗрдЦреЗрдВ

### Results рдЕрдЪреНрдЫреЗ рдирд╣реАрдВ рд╣реИрдВ?
- More training data use рдХрд░реЗрдВ
- Hyperparameters tune рдХрд░реЗрдВ
- Features add рдХрд░реЗрдВ

---

## ЁЯОп Next Steps

1. тЬЕ рддреАрдиреЛрдВ notebooks Kaggle рдкрд░ run рдХрд░реЗрдВ
2. тЬЕ `.pkl` files download рдХрд░реЗрдВ
3. тЬЕ рд╕рд╣реА folders рдореЗрдВ place рдХрд░реЗрдВ
4. тЬЕ Backend restart рдХрд░реЗрдВ
5. тЬЕ Test рдХрд░реЗрдВ!

---

## ЁЯУЮ Need Help?

- Kaggle documentation: [kaggle.com/docs](https://www.kaggle.com/docs)
- XGBoost docs: [xgboost.readthedocs.io](https://xgboost.readthedocs.io/)
- Sentence-BERT: [sbert.net](https://www.sbert.net/)

Happy Training! ЁЯЪА
