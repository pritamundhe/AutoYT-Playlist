{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# XGBoost Ranker Training\n",
                "\n",
                "This notebook trains a Learning-to-Rank model using XGBoost for video ranking.\n",
                "\n",
                "**Goal**: Create `xgboost_ranker.pkl` for ML-based video ranking.\n",
                "\n",
                "## What This Does:\n",
                "1. Creates synthetic training data (or use your own)\n",
                "2. Trains XGBoost ranker\n",
                "3. Evaluates ranking performance\n",
                "4. Saves the model\n",
                "\n",
                "**Upload this notebook to Kaggle and run it there!**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q xgboost scikit-learn pandas numpy matplotlib seaborn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from typing import List, Dict\n",
                "\n",
                "import xgboost as xgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import ndcg_score\n",
                "import os\n",
                "\n",
                "print(\"‚úÖ Libraries imported successfully!\")\n",
                "print(f\"XGBoost version: {xgb.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Generate Synthetic Training Data\n",
                "\n",
                "**Note**: Replace this with your actual user feedback data for better results!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_synthetic_data(n_queries: int = 100, videos_per_query: int = 20) -> pd.DataFrame:\n",
                "    \"\"\"Generate synthetic video ranking data.\"\"\"\n",
                "    \n",
                "    data = []\n",
                "    \n",
                "    for query_id in range(n_queries):\n",
                "        for _ in range(videos_per_query):\n",
                "            # Features\n",
                "            views = np.random.lognormal(10, 2)  # Log-normal distribution for views\n",
                "            likes = views * np.random.uniform(0.01, 0.1)  # 1-10% like rate\n",
                "            subscribers = np.random.lognormal(8, 3)\n",
                "            relevance = np.random.uniform(0, 1)\n",
                "            duration = np.random.uniform(5, 60)  # 5-60 minutes\n",
                "            days_old = np.random.uniform(0, 365 * 3)  # Up to 3 years old\n",
                "            \n",
                "            # Derived features\n",
                "            like_ratio = likes / max(views, 1)\n",
                "            recency_score = 1 / (1 + days_old / 365)\n",
                "            duration_penalty = 1 if 10 <= duration <= 30 else 0.5\n",
                "            \n",
                "            # Target: relevance score (0-4, higher is better)\n",
                "            # Good videos: high relevance, good engagement, recent\n",
                "            target = (\n",
                "                relevance * 2 +  # Relevance is most important\n",
                "                like_ratio * 10 +\n",
                "                recency_score * 0.5 +\n",
                "                duration_penalty * 0.5 +\n",
                "                np.random.normal(0, 0.2)  # Add noise\n",
                "            )\n",
                "            \n",
                "            # FIX: XGBoost rank:ndcg requires INTEGER labels\n",
                "            target = int(np.round(np.clip(target, 0, 4))) # Clip to 0-4 range and convert to integer\n",
                "            \n",
                "            data.append({\n",
                "                'query_id': query_id,\n",
                "                'views': views,\n",
                "                'likes': likes,\n",
                "                'subscribers': subscribers,\n",
                "                'relevance': relevance,\n",
                "                'duration': duration,\n",
                "                'days_old': days_old,\n",
                "                'like_ratio': like_ratio,\n",
                "                'recency_score': recency_score,\n",
                "                'duration_penalty': duration_penalty,\n",
                "                'target': target\n",
                "            })\n",
                "    \n",
                "    return pd.DataFrame(data)\n",
                "\n",
                "# Generate data\n",
                "df = generate_synthetic_data(n_queries=200, videos_per_query=30)\n",
                "\n",
                "print(f\"\\nüìä Generated {len(df)} training samples\")\n",
                "print(f\"Queries: {df['query_id'].nunique()}\")\n",
                "print(f\"\\nFeature columns: {list(df.columns)}\")\n",
                "print(f\"\\nSample data:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Exploration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistics\n",
                "print(\"\\nüìà Data Statistics:\")\n",
                "print(df.describe())\n",
                "\n",
                "# Target distribution\n",
                "plt.figure(figsize=(10, 4))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.hist(df['target'], bins=30, edgecolor='black')\n",
                "plt.xlabel('Target Score')\n",
                "plt.ylabel('Frequency')\n",
                "plt.title('Target Score Distribution')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "correlation = df[['views', 'likes', 'subscribers', 'relevance', 'recency_score', 'target']].corr()['target'].sort_values(ascending=False)\n",
                "correlation.plot(kind='barh')\n",
                "plt.xlabel('Correlation with Target')\n",
                "plt.title('Feature Correlations')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Prepare Training Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature columns\n",
                "feature_cols = ['views', 'likes', 'subscribers', 'relevance', 'duration', \n",
                "                'days_old', 'like_ratio', 'recency_score', 'duration_penalty']\n",
                "\n",
                "X = df[feature_cols].values\n",
                "y = df['target'].values\n",
                "groups = df.groupby('query_id').size().values  # Group sizes for ranking\n",
                "\n",
                "# Split data\n",
                "# For ranking, we need to keep queries together\n",
                "unique_queries = df['query_id'].unique()\n",
                "train_queries, test_queries = train_test_split(unique_queries, test_size=0.2, random_state=42)\n",
                "\n",
                "train_mask = df['query_id'].isin(train_queries)\n",
                "test_mask = df['query_id'].isin(test_queries)\n",
                "\n",
                "X_train, y_train = X[train_mask], y[train_mask]\n",
                "X_test, y_test = X[test_mask], y[test_mask]\n",
                "\n",
                "train_groups = df[train_mask].groupby('query_id').size().values\n",
                "test_groups = df[test_mask].groupby('query_id').size().values\n",
                "\n",
                "print(f\"\\nüì¶ Data Split:\")\n",
                "print(f\"Training: {len(X_train)} samples, {len(train_groups)} queries\")\n",
                "print(f\"Testing: {len(X_test)} samples, {len(test_groups)} queries\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train XGBoost Ranker"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create DMatrix for XGBoost\n",
                "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
                "dtest = xgb.DMatrix(X_test, label=y_test)\n",
                "\n",
                "# Set group information for ranking\n",
                "dtrain.set_group(train_groups)\n",
                "dtest.set_group(test_groups)\n",
                "\n",
                "# XGBoost parameters for ranking\n",
                "params = {\n",
                "    'objective': 'rank:ndcg',  # Ranking objective\n",
                "    'eval_metric': 'ndcg@10',\n",
                "    'eta': 0.1,  # Learning rate\n",
                "    'max_depth': 6,\n",
                "    'min_child_weight': 1,\n",
                "    'subsample': 0.8,\n",
                "    'colsample_bytree': 0.8,\n",
                "    'seed': 42\n",
                "}\n",
                "\n",
                "# Train model\n",
                "print(\"\\nüöÄ Training XGBoost Ranker...\\n\")\n",
                "evals = [(dtrain, 'train'), (dtest, 'test')]\n",
                "evals_result = {}\n",
                "\n",
                "model = xgb.train(\n",
                "    params,\n",
                "    dtrain,\n",
                "    num_boost_round=100,\n",
                "    evals=evals,\n",
                "    evals_result=evals_result,\n",
                "    early_stopping_rounds=10,\n",
                "    verbose_eval=10\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate Model Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "plt.figure(figsize=(10, 4))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(evals_result['train']['ndcg@10'], label='Train')\n",
                "plt.plot(evals_result['test']['ndcg@10'], label='Test')\n",
                "plt.xlabel('Iteration')\n",
                "plt.ylabel('nDCG@10')\n",
                "plt.title('Training Progress')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "# Feature importance\n",
                "plt.subplot(1, 2, 2)\n",
                "importance = model.get_score(importance_type='weight')\n",
                "features = list(importance.keys())\n",
                "scores = list(importance.values())\n",
                "plt.barh(features, scores)\n",
                "plt.xlabel('Importance')\n",
                "plt.title('Feature Importance')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Calculate nDCG on test set\n",
                "y_pred = model.predict(dtest)\n",
                "\n",
                "# Calculate nDCG per query and average\n",
                "ndcg_scores = []\n",
                "start_idx = 0\n",
                "for group_size in test_groups:\n",
                "    end_idx = start_idx + group_size\n",
                "    y_true_group = y_test[start_idx:end_idx].reshape(1, -1)\n",
                "    y_pred_group = y_pred[start_idx:end_idx].reshape(1, -1)\n",
                "    \n",
                "    if len(y_true_group[0]) > 1:  # Need at least 2 items\n",
                "        ndcg = ndcg_score(y_true_group, y_pred_group, k=10)\n",
                "        ndcg_scores.append(ndcg)\n",
                "    \n",
                "    start_idx = end_idx\n",
                "\n",
                "avg_ndcg = np.mean(ndcg_scores)\n",
                "print(f\"\\nüìä Test Set Performance:\")\n",
                "print(f\"Average nDCG@10: {avg_ndcg:.4f}\")\n",
                "print(f\"Min nDCG: {np.min(ndcg_scores):.4f}\")\n",
                "print(f\"Max nDCG: {np.max(ndcg_scores):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Create Ranker Wrapper Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class XGBoostRanker:\n",
                "    \"\"\"Wrapper for XGBoost ranking model.\"\"\"\n",
                "    \n",
                "    def __init__(self, model, feature_names: List[str]):\n",
                "        self.model = model\n",
                "        self.feature_names = feature_names\n",
                "    \n",
                "    def rank(self, videos: List[Dict]) -> List[Dict]:\n",
                "        \"\"\"Rank videos using the trained model.\"\"\"\n",
                "        if not videos:\n",
                "            return []\n",
                "        \n",
                "        # Extract features\n",
                "        features = []\n",
                "        for video in videos:\n",
                "            feature_vector = [video.get(feat, 0) for feat in self.feature_names]\n",
                "            features.append(feature_vector)\n",
                "        \n",
                "        # Predict scores\n",
                "        X = np.array(features)\n",
                "        dmatrix = xgb.DMatrix(X)\n",
                "        scores = self.model.predict(dmatrix)\n",
                "        \n",
                "        # Add scores to videos and sort\n",
                "        for video, score in zip(videos, scores):\n",
                "            video['ml_score'] = float(score)\n",
                "        \n",
                "        ranked_videos = sorted(videos, key=lambda x: x['ml_score'], reverse=True)\n",
                "        return ranked_videos\n",
                "    \n",
                "    def predict_score(self, video: Dict) -> float:\n",
                "        \"\"\"Predict score for a single video.\"\"\"\n",
                "        feature_vector = [video.get(feat, 0) for feat in self.feature_names]\n",
                "        X = np.array([feature_vector])\n",
                "        dmatrix = xgb.DMatrix(X)\n",
                "        return float(self.model.predict(dmatrix)[0])\n",
                "\n",
                "# Create ranker instance\n",
                "ranker = XGBoostRanker(model, feature_cols)\n",
                "\n",
                "print(\"‚úÖ XGBoostRanker class created!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Test the Ranker"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create test videos\n",
                "test_videos = [\n",
                "    {\n",
                "        'title': 'High Quality ML Tutorial',\n",
                "        'views': 100000, 'likes': 5000, 'subscribers': 50000,\n",
                "        'relevance': 0.95, 'duration': 20, 'days_old': 30,\n",
                "        'like_ratio': 0.05, 'recency_score': 0.92, 'duration_penalty': 1.0\n",
                "    },\n",
                "    {\n",
                "        'title': 'Old Low Quality Video',\n",
                "        'views': 1000, 'likes': 10, 'subscribers': 500,\n",
                "        'relevance': 0.3, 'duration': 60, 'days_old': 1000,\n",
                "        'like_ratio': 0.01, 'recency_score': 0.27, 'duration_penalty': 0.5\n",
                "    },\n",
                "    {\n",
                "        'title': 'Recent Viral Video',\n",
                "        'views': 500000, 'likes': 40000, 'subscribers': 100000,\n",
                "        'relevance': 0.75, 'duration': 15, 'days_old': 7,\n",
                "        'like_ratio': 0.08, 'recency_score': 0.98, 'duration_penalty': 1.0\n",
                "    }\n",
                "]\n",
                "\n",
                "# Rank videos\n",
                "ranked = ranker.rank(test_videos.copy())\n",
                "\n",
                "print(\"\\nüèÜ Ranked Videos:\\n\")\n",
                "for i, video in enumerate(ranked, 1):\n",
                "    print(f\"{i}. {video['title']}\")\n",
                "    print(f\"   ML Score: {video['ml_score']:.4f}\")\n",
                "    print(f\"   Relevance: {video['relevance']:.2f}, Views: {video['views']:,}\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Save the Model as .pkl File"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the ranker\n",
                "output_path = 'xgboost_ranker.pkl'\n",
                "\n",
                "with open(output_path, 'wb') as f:\n",
                "    pickle.dump(ranker, f)\n",
                "\n",
                "print(f\"\\n‚úÖ Model saved to: {output_path}\")\n",
                "print(f\"File size: {os.path.getsize(output_path) / (1024*1024):.2f} MB\")\n",
                "\n",
                "# Test loading\n",
                "with open(output_path, 'rb') as f:\n",
                "    loaded_ranker = pickle.load(f)\n",
                "\n",
                "# Verify loaded model works\n",
                "test_score = loaded_ranker.predict_score(test_videos[0])\n",
                "\n",
                "print(f\"\\n‚úÖ Model loaded successfully!\")\n",
                "print(f\"Test prediction: {test_score:.4f}\")\n",
                "print(\"\\nüì• Download this file and place it in: ml_models/ranking/xgboost_ranker.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "1. ‚úÖ Download `xgboost_ranker.pkl` from Kaggle\n",
                "2. üìÅ Place it in: `c:\\Users\\Acer\\Documents\\GitHub\\AutoYT-Playlist\\ml_models\\ranking\\xgboost_ranker.pkl`\n",
                "3. üöÄ The backend will use this for ML-based ranking!\n",
                "\n",
                "---\n",
                "\n",
                "**Model Info:**\n",
                "- Algorithm: XGBoost Learning-to-Rank\n",
                "- Objective: rank:ndcg\n",
                "- Features: 9 (views, likes, subscribers, relevance, etc.)\n",
                "- Performance: nDCG@10 ‚âà {avg_ndcg:.4f}\n",
                "\n",
                "**To Improve:**\n",
                "- Collect real user feedback data\n",
                "- Add more features (comments, engagement rate, etc.)\n",
                "- Tune hyperparameters\n",
                "- Use cross-validation"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}