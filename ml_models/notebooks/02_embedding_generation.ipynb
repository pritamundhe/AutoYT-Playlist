{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Embedding Generation for Relevance Scoring\n",
                "\n",
                "This notebook creates pre-computed embeddings for fast relevance scoring.\n",
                "\n",
                "**Goal**: Create `embeddings.pkl` for semantic similarity calculations.\n",
                "\n",
                "## What This Does:\n",
                "1. Loads Sentence-BERT model\n",
                "2. Creates an embedding generator\n",
                "3. Saves the model for offline use\n",
                "\n",
                "**Upload this notebook to Kaggle and run it there!**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q sentence-transformers transformers torch scikit-learn numpy"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "import numpy as np\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "import os\n",
                "\n",
                "print(\"‚úÖ Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Sentence-BERT Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pre-trained Sentence-BERT model\n",
                "model_name = 'all-MiniLM-L6-v2'  # Fast and accurate\n",
                "print(f\"Loading model: {model_name}...\")\n",
                "\n",
                "embedder = SentenceTransformer(model_name)\n",
                "\n",
                "print(f\"‚úÖ Model loaded!\")\n",
                "print(f\"Embedding dimension: {embedder.get_sentence_embedding_dimension()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create Embedding Wrapper Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class EmbeddingGenerator:\n",
                "    \"\"\"Wrapper for sentence embeddings with caching.\"\"\"\n",
                "    \n",
                "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
                "        self.model = SentenceTransformer(model_name)\n",
                "        self.cache = {}\n",
                "    \n",
                "    def encode(self, texts, use_cache: bool = True):\n",
                "        \"\"\"Generate embeddings for text(s).\"\"\"\n",
                "        if isinstance(texts, str):\n",
                "            texts = [texts]\n",
                "            single = True\n",
                "        else:\n",
                "            single = False\n",
                "        \n",
                "        embeddings = []\n",
                "        for text in texts:\n",
                "            if use_cache and text in self.cache:\n",
                "                embeddings.append(self.cache[text])\n",
                "            else:\n",
                "                emb = self.model.encode(text, convert_to_numpy=True)\n",
                "                if use_cache:\n",
                "                    self.cache[text] = emb\n",
                "                embeddings.append(emb)\n",
                "        \n",
                "        embeddings = np.array(embeddings)\n",
                "        return embeddings[0] if single else embeddings\n",
                "    \n",
                "    def similarity(self, text1: str, text2: str) -> float:\n",
                "        \"\"\"Calculate cosine similarity between two texts.\"\"\"\n",
                "        emb1 = self.encode(text1)\n",
                "        emb2 = self.encode(text2)\n",
                "        return cosine_similarity([emb1], [emb2])[0][0]\n",
                "    \n",
                "    def clear_cache(self):\n",
                "        \"\"\"Clear embedding cache.\"\"\"\n",
                "        self.cache.clear()\n",
                "\n",
                "print(\"‚úÖ EmbeddingGenerator class defined!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Test the Embedding Generator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize generator\n",
                "generator = EmbeddingGenerator()\n",
                "\n",
                "# Test with sample texts\n",
                "topic = \"Introduction to Machine Learning\"\n",
                "video_titles = [\n",
                "    \"Machine Learning Tutorial for Beginners\",\n",
                "    \"Deep Learning Explained\",\n",
                "    \"Introduction to ML - Complete Course\",\n",
                "    \"Python Programming Basics\",\n",
                "    \"What is Machine Learning? ML Explained\"\n",
                "]\n",
                "\n",
                "print(f\"\\nüìä Similarity scores for topic: '{topic}'\\n\")\n",
                "for title in video_titles:\n",
                "    score = generator.similarity(topic, title)\n",
                "    print(f\"{score:.4f} - {title}\")\n",
                "\n",
                "print(f\"\\n‚úÖ Cache size: {len(generator.cache)} embeddings\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Batch Embedding Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test batch encoding\n",
                "sample_texts = [\n",
                "    \"Linear Regression in Machine Learning\",\n",
                "    \"Neural Networks and Deep Learning\",\n",
                "    \"Classification Algorithms Tutorial\",\n",
                "    \"Gradient Descent Optimization\"\n",
                "]\n",
                "\n",
                "batch_embeddings = generator.encode(sample_texts)\n",
                "\n",
                "print(f\"\\nüì¶ Batch encoding results:\")\n",
                "print(f\"Input: {len(sample_texts)} texts\")\n",
                "print(f\"Output shape: {batch_embeddings.shape}\")\n",
                "print(f\"Embedding dimension: {batch_embeddings.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save the Model as .pkl File"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the embedding generator\n",
                "output_path = 'embeddings.pkl'\n",
                "\n",
                "with open(output_path, 'wb') as f:\n",
                "    pickle.dump(generator, f)\n",
                "\n",
                "print(f\"\\n‚úÖ Model saved to: {output_path}\")\n",
                "print(f\"File size: {os.path.getsize(output_path) / (1024*1024):.2f} MB\")\n",
                "\n",
                "# Test loading\n",
                "with open(output_path, 'rb') as f:\n",
                "    loaded_generator = pickle.load(f)\n",
                "\n",
                "# Verify loaded model works\n",
                "test_score = loaded_generator.similarity(\n",
                "    \"Machine Learning Basics\",\n",
                "    \"Introduction to ML Tutorial\"\n",
                ")\n",
                "\n",
                "print(f\"\\n‚úÖ Model loaded successfully!\")\n",
                "print(f\"Test similarity score: {test_score:.4f}\")\n",
                "print(\"\\nüì• Download this file and place it in: ml_models/nlp/embeddings.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Performance Benchmark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# Benchmark encoding speed\n",
                "test_texts = [f\"Sample text number {i}\" for i in range(100)]\n",
                "\n",
                "start = time.time()\n",
                "embeddings = loaded_generator.encode(test_texts, use_cache=False)\n",
                "elapsed = time.time() - start\n",
                "\n",
                "print(f\"\\n‚ö° Performance Benchmark:\")\n",
                "print(f\"Encoded {len(test_texts)} texts in {elapsed:.2f} seconds\")\n",
                "print(f\"Speed: {len(test_texts)/elapsed:.1f} texts/second\")\n",
                "print(f\"Average: {elapsed/len(test_texts)*1000:.1f} ms per text\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "1. ‚úÖ Download `embeddings.pkl` from Kaggle\n",
                "2. üìÅ Place it in: `c:\\Users\\Acer\\Documents\\GitHub\\AutoYT-Playlist\\ml_models\\nlp\\embeddings.pkl`\n",
                "3. üöÄ The backend will use this for fast relevance scoring!\n",
                "\n",
                "---\n",
                "\n",
                "**Model Info:**\n",
                "- Model: `all-MiniLM-L6-v2`\n",
                "- Embedding Size: 384 dimensions\n",
                "- Speed: ~100-200 texts/second on CPU\n",
                "- Use Case: Semantic similarity for video relevance scoring"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}